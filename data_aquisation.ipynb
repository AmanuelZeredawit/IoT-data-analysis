{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition\n",
    "Let's get our first set of IoT data.\n",
    "\n",
    "You will get started by consuming an environmental API provided by a public community. The API consists of multiple endpoints, and you will start by consuming the temperature data. The data is in 10-minute intervals and limited historical data is available.\n",
    "\n",
    "You will use requests to download the last 5 records. Since the endpoint provides json encoded data, you can use .json() on the response object to get a python object (in this case a list).\n",
    "\n",
    "Then you convert the list to a pandas DataFrame to be able to easily work with the data.\n",
    "\n",
    "The constant URL to consume data from has been defined for you.\n",
    "\n",
    "Instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'no Route matched with those values'}\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Download data from URL\n",
    "url = \"https://demo.datacamp.com/api/temp?count=3\"\n",
    "res = requests.get(url)\n",
    "\n",
    "# Convert the result\n",
    "data_temp = res.json()\n",
    "print(data_temp)\n",
    "\n",
    "# Convert json data to DataFrame\n",
    "#df_temp = pd.DataFrame(data_temp)\n",
    "\n",
    "#print(df_temp.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### acquire data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load URL to DataFrame\n",
    "df_temp = pd.read_json(URL)\n",
    "\n",
    "# Print first 5 rows\n",
    "print(df_temp.head(5))\n",
    "\n",
    "# Print datatypes\n",
    "print(df_temp.dtypes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data\n",
    "After consuming an API endpoint, it's often desirable to store the data to disk.\n",
    "\n",
    "Some of the reasons we might want to store data are:\n",
    "\n",
    "archive reproducible results\n",
    "train ML Models\n",
    "You will now consume the same api as you did in previous exercises, but this time you will store the data in both JSON and CSV format.\n",
    "\n",
    "After running this code (not via submit Answer) you can also verify the data you saved using !head filename.\n",
    "\n",
    "URL has been defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load URL to DataFrame\n",
    "df_temp = pd.read_json(URL)\n",
    "\n",
    "# Save DataFrame as json\n",
    "df_temp.to_json(\"temperature.json\", orient=\"records\")\n",
    "\n",
    "# Save DataFrame as csv without index\n",
    "df_temp.to_csv(\"temperature.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from file\n",
    "The data you will work with now includes additional columns about the environment like humidity and air pressure. All data can be consumed seperately from the public API, and I've gathered, combined and stored 3 months for this course.\n",
    "\n",
    "After having acquired and saved the data to disk, you should have a look at what was actually downloaded and stored.\n",
    "\n",
    "You'll now load the data from CSV and JSON, print the head and look at the DataFrame summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read file\n",
    "df_env = pd.read_csv('environmental.csv',  parse_dates=['timestamp'])\n",
    "df = pd.read_json('environmental.json', orient = 'records')\n",
    "\n",
    "# Print head\n",
    "print(df_env.head())\n",
    "\n",
    "# Print DataFrame info\n",
    "print(df_env.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MQTT single message\n",
    "Imagine the following scenario: You have been given an MQTT Broker address and a topic name, and you are supposed to write some code to store the contents of the Datastream.\n",
    "\n",
    "First, you should check what format the messages will be in by consuming a single message.\n",
    "\n",
    "You can then print and inspect the message to determine how to process the data further.\n",
    "\n",
    "This will be our basis for the next exercise, where we will be subscribing to the data stream and collecting multiple messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mqtt library\n",
    "import paho.mqtt.subscribe as subscribe\n",
    "\n",
    "# Retrieve one message\n",
    "msg = subscribe.simple(\"datacamp/iot/simple\", hostname=\"mqtt.datacamp.com\")\n",
    "\n",
    "# Print topic and payload\n",
    "print(f\"{msg.topic}, {msg.payload}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datastream\n",
    "You will now take an MQTT Data stream and append each new data point to the list store.\n",
    "\n",
    "Using the library paho.mqtt, you can subscribe to a data stream using subscribe.callback().\n",
    "\n",
    "Each new message will result in one call to our function, which is required to have the following arguments:\n",
    "\n",
    "client, the client instance for this callback\n",
    "userdata, the private user data set when creating the instance\n",
    "message, an instance of MQTTMessage. For this exercise, payload is the only attribute we're interested in.\n",
    "You need to parse the data as JSON string using json.loads() and append it the list store. You'll then convert this to a DataFrame and store the DataFrame as CSV file.\n",
    "\n",
    "json, pandas as pd, MQTT_HOST and topic are available in your session.\n",
    "\n",
    "Instructions 1/2\n",
    "50 XP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to call by callback method\n",
    "def on_message(client, userdata, message):\n",
    "    # Parse the message.payload\n",
    "    data = json.loads(message.payload)\n",
    "    store.append(data)\n",
    "\n",
    "# Connect function to mqtt datastream\n",
    "subscribe.callback(on_message,topics=\"datacamp/roomtemp\", hostname=MQTT_HOST)\n",
    "\n",
    "df = pd.DataFrame(store)\n",
    "print(df.head())\n",
    "\n",
    "# Store DataFrame to csv, skipping the index\n",
    "df.to_csv('datastream.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95623029550572310fa36d1f4acbebb50f59296794335bcd76b8217138a25cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
